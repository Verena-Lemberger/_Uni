library(tidyverse)
library(ggplot2)
library(Rmisc)
laptops_unclean <- loadRData("data/laptops_unclean.RData")
# https://stackoverflow.com/questions/5577221/how-can-i-load-an-object-into-a-variable-name-that-i-specify-from-an-r-data-file
loadRData <- function(fileName){
#loads an RData file, and returns it
load(fileName)
get(ls()[ls() != "fileName"])
}
library(tidyverse)
library(ggplot2)
library(Rmisc)
laptops_unclean <- loadRData("data/laptops_unclean.RData")
weatherAUS <- read.csv("data/weatherAUS.csv")
data_clean <- weatherAUS %>% select(Humidity9am, Humidity3pm) %>% na.omit()
x <- data_clean$Humidity3pm # FYI X
y <- data_clean$Humidity9am # Y
# Create and fit your linear regression model
linear_model <- lm(x~y)
linear_model
# Assign and print predictions
preds <- predict(linear_model)
head(preds)
# Plot your fit to visualize your model
ggplot(data = linear_model, mapping = aes(x=x, y=y)) + geom_point()
# Assign and print coefficient
coef_lm <- cor.test(x,y,method="pearson")
coef_lm
# Humidity3pm und Humidity9am korrelieren moderat miteinander. Im Plot können wir ebenso eine Heteroskedastizität erkennen, weil mit zunehmender Luftfeuchtigkeit (3pm) gehen die Werte y-Werte immer stärker auseinander. Dies bedeutet, dass die Vorhersagekraft von y, ausgehend von x, geringer wird, je größer der Wert von x ist.
# nicht so heterodetask wie zueste gedacht
# R-squared score
# https://de.wikipedia.org/wiki/Bestimmtheitsma%C3%9F#Als_quadrierter_Korrelationskoeffizient
r2 <- coef_lm$estimate ^ 2 # cbr() ° 2
r2
# Wir können den Koeffizienten nehmen, weil wir eine linçceare Regression haben (deshalb können wir auch den Pearson-Koeffizient verwenden).
# Je geringer die Abweichung der Residuen zum Modell ist, desto näher ist der Wert von R2 an 1 ist.R2 gibt an wie gut die unabhängige(n) Variable(n) die abhängige Variable prognoszitieren können.
# get the mean of y
meanY <- mean(y)
meanY
# get the errors
error <- y - preds
# Mean squared error
rsme = sqrt(mean(error^2))
rsme
# Der RMSE ist 18.13525 und besagt aus, dass im Durchschnitt unser Fehler zwischen tatsächlicher Beobachtung und Prediction sich um 18 Punkte voneinander unterscheiden. Der durchschnittliche Wert der tatsächlichen Werte ist 68.79409, ein Fehler von 18 ist demnach sehr hoch. Wir können deshalb davon ausgehen, dass unser Modell keine besonders guten vorhersagen liefert.
# Mean absolute error
mae = mean(abs(error))
mae
# Der durchschnittliche Absolute Fehler ist der durchschnittliche Betrag aller Fehler. Ebenso wie der RMSE kann er Auskunf über die Genauigkeit unseres Modells geben. Der MAE ist in unserem Fall 17.36871 und ebenso wie der RMSE hoch, was auf eine hohe Fehlerquote unseres Modells rückfolgern lässt.
# Identify and print the the rows with null values
clean <- laptops_unclean %>% filter(!is.na(Price_euros))
nulls <- laptops_unclean %>% filter(is.na(Price_euros))
nulls
# calculate median
medianDF <- laptops_unclean %>% filter(!is.na(Price_euros))
medianDF <- median(medianDF$Price_euros)
medianDF
# Impute constant value 0 and print the head
laptops_impute_0 <- laptops_unclean %>% mutate(Price_euros = replace(Price_euros, is.na(Price_euros), 0))
head(laptops_impute_0)
# Impute median price and print the head
laptops_impute_med <- laptops_unclean %>% mutate(Price_euros = replace(Price_euros, is.na(Price_euros), medianDF))
head(laptops_impute_med)
# Das Ändern der fehlenden Werte hat Auswirkungen auf die Statistik des Data Sets. Bspw. ändert sich der Mean und der Median wenn man die Werte entfernt oder ersetzt. Beim Einsetzen des Means wird bspw. auch die Varianz kleiner, da die Abweichung somit gleich 0 ist.
# 1291 NA -> falscher Datensatz !!!!!!
length(clean)
price <- laptops_unclean %>% filter(!is.na(Price_euros))
price <- price$Price_euros
# Calculate the mean and std
laptops_price_mean <- mean(price)
laptops_price_std <- sd(price)
laptops_price_mean
laptops_price_std
threeSDS = laptops_price_std * 3
# Compute and print the upper and lower threshold
cut_off <- c(laptops_price_mean - threeSDS, laptops_price_mean + threeSDS)
cut_off
# Da es sich um Preise handelt der Preis nicht negativ sein kann, ist die untere Grenze automatisch 0 und nicht -977.1729.
# 3 Standardabweichungen unter 0 ist kein Outlier
# Identify and print rows with outliers
outliers <- laptops_unclean %>% filter(Price_euros > cut_off[2])
outliers
# Drop the rows from the dataset
df_clean <- laptops_unclean %>% filter(Price_euros < cut_off[2])
head(df_clean)
X <- c(8.6, 14.2, 15.1, 17.5, 16.2,  5.8, 20.3,  2.5, 15.4, 22.2, 30.4,
11. , 21.7, 25.5, 13.4, 25.2, 10.6, 26.7, 20.5)
y <- c(8.6, 14.2, 15.1, 17.5, 16.2,  5.8, 20.3,  2.5, 15.4, 22.2, 30.4,
11. , 21.7, 25.5, 13.4, 25.2, 10.6, 26.7, 20.5)
preds <- c(8.6, 14.2, 15.1, 17.5, 16.2,  5.8, 20.3,  2.5, 15.4, 22.2, 30.4,
11. , 21.7, 25.5, 13.4, 25.2, 10.6, 26.7, 20.5)
preds2 <- c(15.53525198, 15.53535007, 15.55148727, 15.72947367, 15.82907881,
17.73831971, 19.20364488, 21.48164064, 22.37381012, 24.95533779,
28.91800569, 28.68313159, 28.23278614, 26.59000134, 27.16358784,
31.52912842, 28.1403767 , 22.11067348, 29.29891384)
linear_model_2 <- lm(X~y)
# Use X and y to create a scatterplot
p1 <- ggplot(data = linear_model_2, mapping = aes(x=X, y=y)) + geom_point()
# Add your model predictions to the scatter plot with preds (line plot)
p2 <- ggplot(data = linear_model_2, mapping = aes(x=X, y=preds)) + geom_line()
# Add the higher-complexity model predictions as well
p3 <- ggplot(data = linear_model_2, mapping = aes(x=X, y=preds2)) + geom_line()
mp <- multiplot(p1, p2, p3, cols = 2)
data <- airquality
head(data)
# see how many rows with NA values we have
# depending on how many there are, replace the values or delete them
airquality_cleaned = NULL
set.seed(1910837830) # Your id
trn_data <- NULL # 70%
tst_data <- NULL # 30%
nobs_tst <- NULL # number of observations in test
# plot here
# anschauen mit view Befehl in R
# montas-variablen nicht in nummern -> dezember ist 12 mal mehr wert als Januar 1
# plot
# pair plot
# Lineares Model (Polynom grad 1)
mod_1 <- NULL
# Interpretation des Outputs von R von Modell 1 (möglichst vollständig/relevant, Koeffizient(en),...)
# polynommodell von grad 1 ist eine gerade (lineare regression)
# nur eines interpretieren
mod_2 <- NULL
#... (ggf. tidy)
# alle 5 modelle bis mod_5
# code
predict_degree_3_89 <- NULL
# Prediction
one_pred_train <- NULL
one_pred_tst <- NULL
#... (verwendung ggf. von broom/tidy)
library(FNN)
mod_knn <- NULL
rmse_trn_1 <- NULL
rmse_tst_1 <- NULL
# skalierung der modelle ist wichtig (dollar vs. 1000 irgendwas)
#...
r2_trn_1 <- NULL
#...
library(knitr)
library(kableExtra)
# your code
# Identify and print the the rows with null values
clean <- laptops_unclean %>% filter(!na.omit(Price_euros)) # na.omit()
# Identify and print the the rows with null values
clean <- filter(!na.omit(laptops_unclean$Price_euros)) # na.omit()
price <- laptops_unclean$Price_euros %>% na.omit() %>% length()
price <- price$Price_euros
# Identify and print the the rows with null values
clean <- laptops_unclean$Price_euros %>% na.omit() %>% length()
nulls <- laptops_unclean %>% filter(is.na(Price_euros))
nulls
# calculate median
medianDF <- laptops_unclean %>% filter(!is.na(Price_euros))
medianDF <- median(medianDF$Price_euros)
medianDF
# Impute constant value 0 and print the head
laptops_impute_0 <- laptops_unclean %>% mutate(Price_euros = replace(Price_euros, is.na(Price_euros), 0))
head(laptops_impute_0)
# Impute median price and print the head
laptops_impute_med <- laptops_unclean %>% mutate(Price_euros = replace(Price_euros, is.na(Price_euros), medianDF))
head(laptops_impute_med)
# Das Ändern der fehlenden Werte hat Auswirkungen auf die Statistik des Data Sets. Bspw. ändert sich der Mean und der Median wenn man die Werte entfernt oder ersetzt. Beim Einsetzen des Means wird bspw. auch die Varianz kleiner, da die Abweichung somit gleich 0 ist.
# 1291 NA -> falscher Datensatz !!!!!!
length(clean)
# Identify and print the the rows with null values
clean <- laptops_unclean$Price_euros %>% na.omit() %>% length()
nulls <- laptops_unclean %>% filter(is.na(Price_euros))
nulls
# calculate median
medianDF <- laptops_unclean %>% filter(!is.na(Price_euros))
medianDF <- median(medianDF$Price_euros)
medianDF
# Impute constant value 0 and print the head
laptops_impute_0 <- laptops_unclean %>% mutate(Price_euros = replace(Price_euros, is.na(Price_euros), 0))
head(laptops_impute_0)
# Impute median price and print the head
laptops_impute_med <- laptops_unclean %>% mutate(Price_euros = replace(Price_euros, is.na(Price_euros), medianDF))
head(laptops_impute_med)
# Das Ändern der fehlenden Werte hat Auswirkungen auf die Statistik des Data Sets. Bspw. ändert sich der Mean und der Median wenn man die Werte entfernt oder ersetzt. Beim Einsetzen des Means wird bspw. auch die Varianz kleiner, da die Abweichung somit gleich 0 ist.
# 1291 NA -> falscher Datensatz !!!!!!
clean
library(statistics4ds)
library(tidyverse)
# data types erkennen
data <- read_csv("/data/wisc-tst.csv")
# data types erkennen
data <- read_csv("data/wisc-tst.csv")
heads(data)
install.packages("caret")
