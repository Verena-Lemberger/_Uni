---
title: "Regression und Prädiktion"
author: "Sascha Metzger - 1910837830"
date: '2019-01-01 (updated: `r Sys.Date()`)'
output:
  html_document:
    df_print: paged
subtitle: Algorithmik und Statistik 1
institute: FH Kufstein
---


```{r setup}
library(FNN)
library(knitr)
library(kableExtra)
library(tidyverse)
library(ggplot2)
library(GGally)
library(Rmisc)
library(broom)
library(FNN)
```

```{r}
# https://stackoverflow.com/questions/5577221/how-can-i-load-an-object-into-a-variable-name-that-i-specify-from-an-r-data-file
loadRData <- function(fileName){
#loads an RData file, and returns it
    load(fileName)
    get(ls()[ls() != "fileName"])
}

calc_rmse = function(actual, predicted) {
  sqrt(mean((actual - predicted) ^ 2))
}

laptops_unclean <- loadRData("data/laptops_unclean.RData")
weatherAUS <- read.csv("data/weatherAUS.csv")
```


# Aufgabe 1: Lineare Regression [5 Punkte]
In dieser Übung implementieren Sie ein einfaches lineares Regressionsmodell. Machen Sie sich bereit für Vorhersagen, visualisieren Sie die Modellanpassung und analysieren Sie die Formel, mit der Sie Ihre Anpassung generieren.

Mittlerweile sind Sie wahrscheinlich mit dem Wetterdatensatz, den wir verwenden werden, zufrieden. Ihre abhängige Variable ist die Humidity3pm-Funktion.

## Anweisungen
- Weisen Sie der Variablen linear_model ein lm()-Objekt zu; passen Sie Ihr Modell in die nächste Zeile.
- Weisen Sie die Vorhersagen aus Ihrem Modell mit der Funktion predict() `preds` zu; geben Sie die Ergebnisse aus.
- Visualisieren Sie die Beziehung zwischen X und y mit der scatter()-Funktion und zeichnen Sie dann Ihre Vorhersagen darauf auf.
- Weisen Sie den Koeffizienten für Ihre unabhängige Variable zu und geben Sie ihn aus; was bedeutet das?

```{r}
data_clean <- weatherAUS %>% select(Humidity9am, Humidity3pm) %>% na.omit()

x <- data_clean$Humidity3pm 
y <- data_clean$Humidity9am

# Create and fit your linear regression model
linear_model <- lm(x~y)
summary(linear_model)

# Assign and print predictions
preds <- predict(linear_model)
head(preds)

plot(x, y, xlab = "Humidity3pm", ylab = "Humidity9am", pch = 19, frame = FALSE)
abline(linear_model, col = "green")

# Assign and print coefficient 
coef_lm <- cor.test(x,y,method="pearson")
coef_lm

sd(x)
sd(y)

# Humidity3pm und Humidity9am korrelieren moderat miteinander (r = 0.6673878). Im Plot können wir ebenso eine Heteroskedastizität erkennen, weil mit zunehmender Luftfeuchtigkeit (3pm) gehen die Werte y-Werte immer stärker auseinander. Dies bedeutet, dass die Vorhersagekraft von y, ausgehend von x, geringer wird, je größer der Wert von x ist. Allerdings ist die Heteroskedastizität nicht extrem groß.

```




# Aufgabe 2: Evaluierung der Regression [4 Punkte]
Lassen Sie uns das lineare Regressionsmodell, das Sie mit lm() erstellt und trainiert haben, erneut besuchen. Bewerten Sie die Leistung Ihres Modells, das als `linear_model` importiert sein muss, damit Sie es aufrufen können.

Kommen wir zur Berechnung der R-Quadrat-, mittleren quadratischen Fehler- und mittleren absoluten Fehlerwerte für das Modell.

## Anweisungen
- Berechnen und geben Sie die Ergebnisse des R-Quadrats unseres Modells aus.
- Berechnen und geben Sie die Ergebnisse des Mean_squared Errors unseres Modells aus.
- Berechnen und geben Sie die Ergebnisse des Mean_absolute Errors unseres Modells aus.
- Interpretieren Sie die Regression

```{r}
x <- data_clean$Humidity3pm 
y <- data_clean$Humidity9am
preds <- predict(linear_model)

# R-squared score
r2 <- coef_lm$estimate^2
r2
# Wir können den Koeffizienten nehmen, weil wir eine lineare Regression haben (deshalb können wir auch den Pearson-Koeffizient verwenden).
# Je geringer die Abweichung der Residuen zum Modell ist, desto näher ist der Wert von R2 an 1 ist. R2 gibt an wie gut die unabhängige(n) Variable(n) die abhängige Variable prognoszitieren können.

# get the mean of y
meanY <- mean(y)
meanY

# get the errors 
error <- y - preds

# Mean squared error
sme <- mean(error^2)
sme
# Der mittlere quadratische Fehler (MSE) misst die durchschnittliche quadratische Differenz zwischen den geschätzten Werten und dem tatsächlichen Wert. In unserem Fall ist es 328.8872. Der MSE bewertet wie gut ein Prädiktor ist.

# Root Mean squared error
rsme <- sqrt(sme)
rsme

# Mean absolute error
mae <- mean(abs(error))
mae

# Der durchschnittliche Absolute Fehler ist der durchschnittliche Betrag aller Fehler. Ebenso wie der RMSE kann er Auskunf über die Genauigkeit unseres Modells geben. Der MAE ist in unserem Fall 17.36871.

# Der RMSE in unserem Modell liegt bei 18.13525, der MAE Erwartungsgemäß knapp darunter bei 17.36871. Dies deutet darauf hin, dass, ausgehend von unserem Mean von 68.79, unsere Prädiktion nur mittelmäßig ist. 
```






# Aufgabe 3: Behandlung von Nullwerten [3 Punkte]
Lassen Sie uns üben, mit Nullwerten mit unserem Laptops-Datensatz umzugehen, mit dem wir zuvor gearbeitet haben. Sie werden Zeilen mit Nullwerten identifizieren und dann verschiedene Techniken ausprobieren, um dieses Problem zu lösen.

## Anweisungen
- Identifizieren und drucken Sie die Zeilen mit Nullwerten, indem Sie Ihren Data.frame mit der is.null() Funktion schneiden.
- Impute 0 für fehlende Preise; geben Sie den Head aus.
- Passen Sie den Code an, dass der Preis mit dem Median aufgefüllt wird. geben Sie den Head aus.

```{r}
length_unclean <- laptops_unclean$Price_euros %>% length()
length_unclean

# Identify and print the the rows with null values 
## create a new df from all the rows with NA in the Price_euros column
missing_data <- laptops_unclean[ !(laptops_unclean$Price_euros), ]
missing_data_length <- missing_data$Price_euros %>% length()
clean_data_length <- length_unclean - missing_data_length
head(missing_data)
missing_data_length
clean_data_length

# calculate median
clean <- laptops_unclean$Price_euros %>% na.omit()
medianDF_clean <- median(clean)
meanDF_clean <- mean(clean)
medianDF_clean
meanDF_clean

# Impute constant value 0 and print the head
laptops_impute_0 <- laptops_unclean %>% mutate(Price_euros = replace(Price_euros, is.na(Price_euros), 0))
medianDF <- median(laptops_impute_0$Price_euros)
meanDF <- mean(laptops_impute_0$Price_euros)
head(laptops_impute_0)
medianDF
meanDF

# Impute median price and print the head
laptops_impute_med <- laptops_unclean %>% mutate(Price_euros = replace(Price_euros, is.na(Price_euros), medianDF_clean))
medianDF <- median(laptops_impute_med$Price_euros)
meanDF <- mean(laptops_impute_med$Price_euros)
head(laptops_impute_med)
medianDF
meanDF

# Das Ändern der fehlenden Werte hat Auswirkungen auf die Statistik des Data Sets. Insgesamt gibt es 1291 korrekte Datensätze. Der Median des bereinigten Datensets ist 977, der Mean liegt bei 1124.677. 
# Setzt man für die fehlenden Werte 0 ein verringert sich der Median auf 960, da der Datensatz ingesamt mehr Werte enthält und neue, kleinere Werte hinzukommen. Der Mean verringert sich auf 1114.319.
# Beim Einsetzen des Medians ändert sich der insgesamte Median im Vergleich zum bereinigten Datenset nicht (da der gleiche Wert eingesetzt wird), er ist bleibt bei 977. Der Mean verringert sich allerdings geringfügig auf 1123.317.
```




# Aufgabe 4: Identifizierung von Ausreißern [4 Punkte]
Lassen Sie uns mit unserem Laptops-Datensatz weitermachen und einige Ausreißer bekämpfen, die sich verstecken. In dieser Übung werden wir uns an die  Technik halten, anhand von Standardabweichungen zur Identifizierung von Extremwerten, da diese Methode in der Praxis häufiger verwendet wird.

Sie berechnen die deskriptiven Statistiken und Ausreißergrenzen und identifizieren dann die Zeilen mit ihnen, bevor Sie sie aus dem Dataset entfernen. Sie werden hier hauptsächlich mit der Spalte Preis arbeiten.

## Anweisungen
- Berechnen Sie den Mittelwert und die Standardabweichung der Preis-Spalte
- Berechnen Sie die oberen und unteren Grenzen von akzeptablen Werten mit 3 Standardabweichungen
- Berechnen Sie die Outliers, die ausserhalb liegen
- Verwerfen Sie die Outliers

```{r}
price <- laptops_unclean %>% filter(!is.na(Price_euros))
price <- price$Price_euros

# Calculate the mean and std
laptops_price_mean <- mean(price)
laptops_price_std <- sd(price)

laptops_price_mean
laptops_price_std

threeSDS = laptops_price_std * 3 # 3 Standardabweichungen
threeSDS

# Compute and print the upper and lower threshold
cut_off <- c(laptops_price_mean - threeSDS, laptops_price_mean + threeSDS)
cut_off
# Da es sich um Preise handelt der Preis nicht negativ sein kann, ist die untere Grenze automatisch 0 und nicht -977.1729.
# 3 Standardabweichungen unter 0 ist kein Outlier

# Identify and print rows with outliers
outliers <- laptops_unclean %>% filter(Price_euros > cut_off[2])
outliers

# Drop the rows from the dataset
df_clean <- laptops_unclean %>% filter(Price_euros < cut_off[2])
head(df_clean)


```

# Aufgabe 6 [26 Punkte]
Für diese Aufgabe werden wir den Luftqualitätsdatensatz `airquality` verwenden, der ein Standarddatensatz in R ist.

## 6.1 Data Cleaning [1 Punkt]
Dieser Datensatz enthält einige fehlende Daten. Der Einfachheit halber werden wir sie entfernen. Denken Sie darüber nach, warum dies eine vernünftige Sache sein kann oder auch nicht. (Wir werden später auf diese Idee zurückkommen. Für den Moment wollen wir uns auf die Modellierung konzentrieren)

```{r}
data <- airquality
data_length <- nrow(data)
data_length

# see how many rows with NA values we have
# depending on how many there are, replace the values or delete them
summary(data)
# Insgesamt gibt es 44 Werte (Ozone 37 & Solar.R 7) mit fehlenden Werten. Wenn wir alle Werte einfach entfernen würden, würde ein Großteil der Daten verloren gehen. Deshalb müssen wir die Daten ersetzen. 

# Die Spalten Monat und Tag falsch formatiert
typeof(data$Day)
typeof(data$Month)

# Die NA-Werte von Ozon und Solar.R werden mit dem Median der jeweiligen Spalten ersetzt um die Werte nicht zu sehr zu verfälschen
#ozone_median <- data$Ozone %>% na.omit() %>% median()
#solar_r_median <- data$Solar.R %>% na.omit() %>% median()

#airquality_cleaned <- data %>% mutate(Ozone = replace(Ozone, is.na(Ozone), ozone_median))
#airquality_cleaned <- airquality_cleaned %>% mutate(Solar.R = replace(Solar.R, is.na(Solar.R), solar_r_median))

airquality_cleaned <- na.omit(data)


# Tag sollte kein Integer sein, sondern ein Faktor zwischen 1 und 31 (min und max der Spalte)
# airquality_cleaned$Day <- factor(airquality_cleaned$Day, levels=c(1:31), ordered=TRUE)

# Monat sollte ebenfalls kein Integer sein, sondern ein Faktor zwischen 5 und 9
# airquality_cleaned$Month <- factor(airquality_cleaned$Month, levels=5:9, labels=month.abb[5:9], ordered=TRUE)

head(airquality_cleaned)
```

## 6.2 Test-Train Split [2 Punkte]
Jetzt wollen wir einen Testzug mit der Aufteilung der Daten durchführen. Das heißt, wir wollen einen Trainingsdatensatz zur Anpassung unserer Modelle und einen Testdatensatz zur Auswertung unserer Modelle. Da diese Aufteilung auf zufällig ausgewählten Beobachtungen im Datensatz basiert, setzen wir zunächst einen Seed-Wert, um die gleiche Aufteilung wieder reproduzieren zu können.

```{r}
set.seed(1910837830) # Your id

# Kreiert einen Vector mit zufälligen Zeilenummern 
index <- sample(nrow(airquality_cleaned), size = trunc(0.70 * nrow(airquality_cleaned)))
# Neues df mit den Zeilenummern aus dem Index
trn_data <- airquality_cleaned[index, ] # 70% 
# Neues df mit allen Zeilen, welche nicht im Index sind
tst_data <- airquality_cleaned[-index, ] # 30%

# Test ob alles korrekt ist
nobs_trn <- nrow(trn_data)
nobs_tst <- nrow(tst_data)
nobs_trn
nobs_tst
nobs_trn + nobs_tst == nrow(airquality_cleaned)
```
Wie viele Beobachtungen werden in der Testmenge verwendet?
34 Beobachtungen in der Testmenge, 77 im Trainings-Set


## 6.3 EDA [4 Punkte]
Wir haben bereits begonnen, mit diesen Daten zu arbeiten, aber wir sollten wirklich einen Schritt zurücktreten und uns eine Frage stellen. **Was sind diese Daten?** Wann immer Sie sich diese Frage stellen, sollten Sie sich die Daten "anschauen". Man sollte drei Dinge tun:

- Lesen Sie die Metadaten, in diesem Fall die R-Dokumentation.
  - Woher kommen diese Daten?
  - Was ist eine Beobachtung in diesem Datensatz?
  - Was sind die Variablen in diesem Datensatz?
- Betrachten Sie die Daten in tabellarischer Form. Dies kann durch Anklicken des Datensatzes im RStudio Enviroment-Panel oder durch Verwendung des View() Befehls auf dem Datensatz erfolgen.
  - Was ist der Typ der einzelnen Variablen?
  - Sind kategorische Variablen als Faktoren kodiert?
- Stellen Sie die Daten dar (Plots).

**Beantworten Sie die ersten beiden Fragen!**
1)
Die Daten sind tägliche Messungen der Luftqualität in New York von Mai bis September 1973. Sie wurden vom New York State Department of Conservation (Ozondaten) und vom National Weather Service (meteorologische Daten) bezogen.
Das df hat 153 Beobachtungen und sechs Variablen:
1:	Ozone	
2:	Solar.R	
3:	Wind	
4:	Temp	
5:	Month	
6:	Day	

2)
Im originalen Datensatz sind alle Spalten numerisch. Bei den ersten vier Variablen ist dies in Ordnung, doch die Tage und Monate sollten als Faktoren formatiert sein, da ansonsten keine korrekte Analyse des Datensatzes möglich ist (bspw. würde Dezember "besser" bewertet werden als der Januar, da 12 > 01) 

**----**

Erstellen Sie ein Diagramm, das alle möglichen Streudiagramme von zwei Variablen im Trainingsdatensatz zeigt.

```{r}
plot(trn_data)
```



Da wir uns auf die Vorhersage von `Ozone` mit Hilfe von `Temp` konzentrieren werden, erstellen Sie eine Streudiagramm, das nur diese Beziehung anhand der Trainingsdaten zeigt

```{r}
ggpairs(trn_data, columns=c("Temp", "Ozone"), progress = F) + ggtitle("Airquality Dataset - Ozone & Temp")
```



## 6.4 Modelle [6 Punkte]
Passen Sie insgesamt fünf Polynommodelle an die Trainingsdaten an, die zur Vorhersage von Ozon aus Temp. verwendet werden können. Verwenden Sie Polynomgrade von 1 bis 5.

```{r}
# Lineares Model (Polynom grad 1)
month <- trn_data$Month
mod_1 <- lm(Ozone ~ poly(Temp, 1), data = trn_data)

df <- data.frame(Temp = trn_data$Temp, Ozone = trn_data$Ozone, mod_1 = mod_1$fitted.values)
ggplot(df, aes(x=Temp, y=Ozone, colour = factor(month))) + geom_point() + xlab("Temp") + ylab("Ozone") + geom_line(df, mapping = aes(x=Temp, y=mod_1), color="green")


# Interpretation des Outputs von R von Modell 1 (möglichst vollständig/relevant, Koeffizient(en),...)
plot(mod_1$residuals)
qqnorm(mod_1$residuals)
qqline(mod_1$residuals)

summary(mod_1)
# correlation
cor(y=mod_1$fitted.values, trn_data$Ozone, method = "pearson")

# Der Residienplot weißt keine besonderen Auffälligkeiten in der Verteilung der Residuen auf. Dies deutet darauf hin, dass die gefitteten Werte und die Residuen unkorreliert sind.
# Der QQ-Plot deutet auf eine Normalverteilung hin, auch wenn die Werte an den extremen weit von der Linie entfernt sind (Ausreißer / Messfehler).
# Der Korrelationskoeffizient deutet auf eine moderate, postive Korrelation zwischen Ozon und Temperatur hin.
# Der Residuen-Standard-Error liegt bei 24,19, r2 bei 0,4527, r bei 0,673. All diese Werte lassen vermuten, dass unser Modell nicht besonders gut performen wird. 
```

```{r}
mod_2 <- lm(Ozone ~ poly(Temp, 2), data = trn_data)
mod_3 <- lm(Ozone ~ poly(Temp, 3), data = trn_data)
mod_4 <- lm(Ozone ~ poly(Temp, 4), data = trn_data)
mod_5 <- lm(Ozone ~ poly(Temp, 5), data = trn_data)

df$mod_2 = mod_2$fitted.values
df$mod_3 = mod_3$fitted.values
df$mod_4 = mod_4$fitted.values
df$mod_5 = mod_5$fitted.values

ggplot(df, aes(x=Temp, y=Ozone, colour = factor(month))) + geom_point() + xlab("Temp") + ylab("Ozone") +
  geom_line(df, mapping = aes(x=Temp, y=mod_2), color="green") + 
  geom_line(df, mapping = aes(x=Temp, y=mod_3), color="orange") + 
  geom_line(df, mapping = aes(x=Temp, y=mod_4), color="blue") + 
  geom_line(df, mapping = aes(x=Temp, y=mod_5), color="tomato") 
```



Vorhersage von Ozon für eine Temperatur von 89 Grad Fahrenheit unter Verwendung des Polynommodells mit drei Graden.

```{r}
month <- trn_data$Month
predict_degree_3_89 <- predict(mod_3, data.frame(Temp = 89))
predict_degree_3_89
```

```{r, eval=F}
predict_degree_3_89.sol <- predict(mod_3, data.frame(Temp = 89)) #74.40082
predict_degree_3_89.sol
```


Prädiktieren Sie alle 5 Modelle für Train/Test-Daten

```{r}

# Prediction
one_pred_train <- predict(mod_1, newdata = trn_data)
one_pred_tst <- predict(mod_1, newdata = tst_data)

two_pred_train <- predict(object = mod_2, newdata = trn_data)
two_pred_tst <- predict(object = mod_2, newdata = tst_data)

three_pred_train <- predict(object = mod_3, newdata = trn_data)
three_pred_tst <- predict(object = mod_3, newdata = tst_data)

four_pred_train <- predict(object = mod_4, newdata = trn_data)
four_pred_tst <- predict(object = mod_4, newdata = tst_data)

five_pred_train <- predict(object = mod_5, newdata = trn_data)
five_pred_tst <- predict(object = mod_5, newdata = tst_data)
```

## 6.5  KNN Modell [3 Punkte]
Verwenden Sie KNN mit `k = 5`, um Vorhersagen für jede der Beobachtungen sowohl im Train- als auch in den Testdatensätzen zu treffen. Speichern Sie die Ergebnisse in Vektoren mit den Namen `knn_pred_trn` und `knn_pred_tst`.

Dazu benötigen Sie die Funktion `knn.reg()` aus dem FNN-Paket. Die knn.reg() unterscheidet sich sehr von der Funktion lm(). Prüfen Sie die Dokumentation!

```{r}
knn_pred_trn = knn.reg(train = trn_data["Temp"], test = trn_data["Temp"], y = trn_data["Ozone"], k =  5)
knn_pred_tst = knn.reg(train = trn_data["Temp"], test = tst_data["Temp"], y = trn_data["Ozone"], k =  5)

# root mean squared error
sqrt(mean((trn_data$Ozone - knn_pred_trn$pred) ^ 2))
sqrt(mean((tst_data$Ozone - knn_pred_tst$pred) ^ 2))

# mean absolute error
mean(abs(trn_data$Ozone - knn_pred_trn$pred))
mean(abs(tst_data$Ozone - knn_pred_tst$pred))

plot(tst_data$Temp, knn_pred_tst$pred, xlab="y", ylab=expression(hat(y)))

```


- Beschreiben Sie kurz KNN
Der KNN-Algorithmus weißt neue Daten basierend auf den Ähnlichkeiten zu den bereits bekannten Daten in Klassen zu. Die Anzahl der Klassen (k) wird im Vorfeld definiert. Will man nun einen neuen Datenpunkt prediktieren, vergleicht der KNN-Algorithmus wie weit diser Datenpunkt von anderen Punkten entfernt ist. Für die Berechnung der Entfernung wird z.B. die Euclidean-Distance oder die Manhatten-Distance verwendt. Schließlich wird mit einem Mehrheitsvotum der Punkt zu einer Klasse zugeordnet. 
Bsp: k = 2. Ist der neue Datenpunkt näher zu Punkten aus der Klasse 1 wird der neue Datenpunkt auch zur Klasse 1 hinzugeordnet

- Interpretieren Sie den Model-Output?
Anhand des Outputs können wir erkennen, dass das Modell einen r2 Faktor von 0.700, einen MAE von 11.78788 und einen MSE 19.24682 hat. Der Plot verdeutlicht die durchschnittliche Leistung unseres Modells weiter. 

## 6.6 Ergebnisse [3 Punkte]
Berechnen Sie sowohl den Trainings- als auch den Test-RMSE für die obigen Modelle unter Verwendung der von Ihnen gespeicherten Vorhersagen

```{r}
rmse_trn_1 <- calc_rmse(actual = trn_data$Ozone, predicted = one_pred_train)
rmse_tst_1 <- calc_rmse(actual = tst_data$Ozone, predicted = one_pred_tst)

# 1
rmse_trn_1
rmse_tst_1


rmse_trn_2 <- calc_rmse(actual = trn_data$Ozone, predicted = two_pred_train)
rmse_tst_2 <- calc_rmse(actual = tst_data$Ozone, predicted = two_pred_tst)

# 2
rmse_trn_2
rmse_tst_2


rmse_trn_3 <- calc_rmse(actual = trn_data$Ozone, predicted = three_pred_train)
rmse_tst_3 <- calc_rmse(actual = tst_data$Ozone, predicted = three_pred_tst)

# 3
rmse_trn_3
rmse_tst_3


rmse_trn_4 <- calc_rmse(actual = trn_data$Ozone, predicted = four_pred_train)
rmse_tst_4 <- calc_rmse(actual = tst_data$Ozone, predicted = four_pred_tst)

# 4
rmse_trn_4
rmse_tst_4


rmse_trn_5 <- calc_rmse(actual = trn_data$Ozone, predicted = five_pred_train)
rmse_tst_5 <- calc_rmse(actual = tst_data$Ozone, predicted = five_pred_tst)

# 5
rmse_trn_5
rmse_tst_5


# Knn
rmse_knn_trn <- calc_rmse(actual = trn_data$Ozone, predicted = knn_pred_trn$pred)
rmse_knn_tst <- calc_rmse(actual = tst_data$Ozone, predicted = knn_pred_tst$pred)

rmse_knn_trn
rmse_knn_tst
```


Berechnen Sie die R2 Scores der Modelle

```{r}
r2_trn_1 <- summary(mod_1)$r.squared
r2_trn_2 <- summary(mod_2)$r.squared
r2_trn_3 <- summary(mod_3)$r.squared
r2_trn_4 <- summary(mod_4)$r.squared
r2_trn_5 <- summary(mod_5)$r.squared
r2_trn_Knn <- cor(knn_pred_trn$pred, trn_data$Ozone) ^ 2

r2_trn_1
r2_trn_2
r2_trn_3
r2_trn_4
r2_trn_5
r2_trn_Knn
#...
```



Erstellen Sie eine Tabelle, die die Ergebnisse der einzelnen Modellanpassungen zusammenfasst. (Die fünf Polynommodelle und das einzelne KNN-Modell.) Notieren Sie für jedes Modell den Modelltyp, den Wert des Abstimmparameters, den Train-RMSE und den Test-RMSE. (Betrachten Sie den Polynomgrad als Abstimmungsparameter.) Das Ergebnis sollte eine Tabelle mit einer Überschrift, sechs Zeilen und vier Spalten sein. Blenden Sie im endgültigen gerenderten Dokument den Code aus, der zur Erstellung der Tabelle verwendet wurde.

Hinweis: Erstellen Sie zuerst einen Datenrahmen und verwenden Sie dann die kable() Funktion aus dem knitr-Paket. 

```{r}
# create a vector with the rmses of the training and test data wo we can plot them
trn_rmse_vector = c(
    rmse_trn_1,
    rmse_trn_2,
    rmse_trn_3,
    rmse_trn_4,
    rmse_trn_5,
    rmse_knn_trn
)
tst_rmses_vector = c(
    rmse_tst_1,
    rmse_tst_2,
    rmse_tst_3,
    rmse_tst_4,
    rmse_tst_5,
    rmse_knn_tst
)

# because table needs a data frame, we need to create it first
data = data.frame(
  method = c("poly", "poly", "poly", "poly", "poly", "knn"),
  tuning = c(1, 2, 3, 4, 5, 5), 
  train  = c(trn_rmse_vector),
  test   = c(tst_rmses_vector)
)
colnames(data) = c("Modelltyp", "Abstimmparameter", "Train-RMSE", "Test-RMSE")
table <- kable(data, format = "html", digits = 2)
kable_styling(table, full_width = FALSE)
```

## 6.7 Plot der Ergebnisse [2 Punkte]
Stellen Sie die obige Streudiagramm von Ozon gegen die Temperaturform wieder her. Fügen Sie zu dieser Darstellung das Polynommodell hinzu, das am besten funktioniert hat, sowie das angepasste KNN-Modell. Können Sie diese Darstellung im gerenderten Dokument zentrieren? Blenden Sie den Code wieder aus, um die Darstellung zu erstellen.

```{r}
ggplot() + geom_point(aes(x=Temp, y=Ozone ), data = trn_data) + xlab("Temp") + ylab("Ozone") + 
  geom_line(aes(x=trn_data$Temp, y=five_pred_train), color="green") + 
  geom_line(aes(x=trn_data$Temp, y=knn_pred_trn$pred), color="orange")
```

## 6.8 Multiple Prädiktoren [5 Punkte]
Bisher haben wir nur einen der verfügbaren Prädiktoren verwendet. Warum nicht alle verwenden? (Vielleicht sollten wir aber nur einige davon verwenden... Wir kommen später noch einmal auf diesen Gedanken zurück.)

[Übung] Fitten Sie ein additives lineares Modell mit Ozon als Antwort und den restlichen Variablen als Prädiktoren ein. Berechnen Sie den Test-RMSE für dieses Modell. Verbessert dies die vorherigen Modelle?

```{r}
mod_6 = lm(Ozone ~ ., data = trn_data)
prediction <- predict(mod_6, tst_data)
calc_rmse(actual = tst_data$Ozone, predicted = prediction)
# Ja, dieses Modell ist mit einem RMSE von 19.14013 besser als alle anderen Modelle vorher. Das beste Modell vorher war das Modell poly 5 mit einem Test-RMSE von 19.48.
```


