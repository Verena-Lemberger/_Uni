---
title: "Regression und Prädiktion"
subtitle: "Algorithmik und Statistik 1"
author: "Sascha Metzger - 1910837830"
institute: "FH Kufstein"
date: "2019-01-01 (updated: `r Sys.Date()`)"
---

```{r}
# https://stackoverflow.com/questions/5577221/how-can-i-load-an-object-into-a-variable-name-that-i-specify-from-an-r-data-file
loadRData <- function(fileName){
#loads an RData file, and returns it
    load(fileName)
    get(ls()[ls() != "fileName"])
}
```

```{r setup}
library(tidyverse)
library(ggplot2)
library(GGally)
library(Rmisc)
laptops_unclean <- loadRData("data/laptops_unclean.RData")
weatherAUS <- read.csv("data/weatherAUS.csv")
```

# Aufgabe 1: Lineare Regression [5 Punkte]
In dieser Übung implementieren Sie ein einfaches lineares Regressionsmodell. Machen Sie sich bereit für Vorhersagen, visualisieren Sie die Modellanpassung und analysieren Sie die Formel, mit der Sie Ihre Anpassung generieren.

Mittlerweile sind Sie wahrscheinlich mit dem Wetterdatensatz, den wir verwenden werden, zufrieden. Ihre abhängige Variable ist die Humidity3pm-Funktion.

## Anweisungen
- Weisen Sie der Variablen linear_model ein lm()-Objekt zu; passen Sie Ihr Modell in die nächste Zeile.
- Weisen Sie die Vorhersagen aus Ihrem Modell mit der Funktion predict() `preds` zu; geben Sie die Ergebnisse aus.
- Visualisieren Sie die Beziehung zwischen X und y mit der scatter()-Funktion und zeichnen Sie dann Ihre Vorhersagen darauf auf.
- Weisen Sie den Koeffizienten für Ihre unabhängige Variable zu und geben Sie ihn aus; was bedeutet das?

```{r}
data_clean <- weatherAUS %>% select(Humidity9am, Humidity3pm) %>% na.omit()

x <- data_clean$Humidity3pm # FYI X
y <- data_clean$Humidity9am # Y

# Create and fit your linear regression model
linear_model <- lm(x~y)
linear_model

# Assign and print predictions
preds <- predict(linear_model)
head(preds)

# Plot your fit to visualize your model
ggplot(data = linear_model, mapping = aes(x=x, y=y)) + geom_point()

# Assign and print coefficient 
coef_lm <- cor.test(x,y,method="pearson")
coef_lm

# Humidity3pm und Humidity9am korrelieren moderat miteinander. Im Plot können wir ebenso eine Heteroskedastizität erkennen, weil mit zunehmender Luftfeuchtigkeit (3pm) gehen die Werte y-Werte immer stärker auseinander. Dies bedeutet, dass die Vorhersagekraft von y, ausgehend von x, geringer wird, je größer der Wert von x ist. Allerdings ist die Heteroskedastizität nicht extrem groß.

```




# Aufgabe 2: Evaluierung der Regression [4 Punkte]
Lassen Sie uns das lineare Regressionsmodell, das Sie mit lm() erstellt und trainiert haben, erneut besuchen. Bewerten Sie die Leistung Ihres Modells, das als `linear_model` importiert sein muss, damit Sie es aufrufen können.

Kommen wir zur Berechnung der R-Quadrat-, mittleren quadratischen Fehler- und mittleren absoluten Fehlerwerte für das Modell.

## Anweisungen
- Berechnen und geben Sie die Ergebnisse des R-Quadrats unseres Modells aus.
- Berechnen und geben Sie die Ergebnisse des Mean_squared Errors unseres Modells aus.
- Berechnen und geben Sie die Ergebnisse des Mean_absolute Errors unseres Modells aus.
- Interpretieren Sie die Regression

```{r}
# R-squared score
# https://de.wikipedia.org/wiki/Bestimmtheitsma%C3%9F#Als_quadrierter_Korrelationskoeffizient
r2 <- coef_lm$estimate ^ 2 # cbr() ° 2
r2
# Wir können den Koeffizienten nehmen, weil wir eine linçceare Regression haben (deshalb können wir auch den Pearson-Koeffizient verwenden). 
# Je geringer die Abweichung der Residuen zum Modell ist, desto näher ist der Wert von R2 an 1 ist.R2 gibt an wie gut die unabhängige(n) Variable(n) die abhängige Variable prognoszitieren können.

# get the mean of y
meanY <- mean(y)
meanY

# get the errors 
error <- y - preds

# Mean squared error
rsme = sqrt(mean(error^2))
rsme
# Der RMSE ist 18.13525 und besagt aus, dass im Durchschnitt unser Fehler zwischen tatsächlicher Beobachtung und Prediction sich um 18 Punkte voneinander unterscheiden. Der durchschnittliche Wert der tatsächlichen Werte ist 68.79409, ein Fehler von 18 ist demnach sehr hoch. Wir können deshalb davon ausgehen, dass unser Modell keine besonders guten vorhersagen liefert.  

# Mean absolute error
mae = mean(abs(error))
mae
# Der durchschnittliche Absolute Fehler ist der durchschnittliche Betrag aller Fehler. Ebenso wie der RMSE kann er Auskunf über die Genauigkeit unseres Modells geben. Der MAE ist in unserem Fall 17.36871 und ebenso wie der RMSE hoch, was auf eine hohe Fehlerquote unseres Modells rückfolgern lässt. 
```






# Aufgabe 3: Behandlung von Nullwerten [3 Punkte]
Lassen Sie uns üben, mit Nullwerten mit unserem Laptops-Datensatz umzugehen, mit dem wir zuvor gearbeitet haben. Sie werden Zeilen mit Nullwerten identifizieren und dann verschiedene Techniken ausprobieren, um dieses Problem zu lösen.

## Anweisungen
- Identifizieren und drucken Sie die Zeilen mit Nullwerten, indem Sie Ihren Data.frame mit der is.null() Funktion schneiden.
- Impute 0 für fehlende Preise; geben Sie den Head aus.
- Passen Sie den Code an, dass der Preis mit dem Median aufgefüllt wird. geben Sie den Head aus.

```{r}
length_unclean <- laptops_unclean$Price_euros %>% length()
length_unclean

# Identify and print the the rows with null values 
## create a new df from all the rows with NA in the Price_euros column
missing_data <- laptops_unclean[ !(laptops_unclean$Price_euros), ]
missing_data_length <- clean_test$Price_euros %>% length()
clean_data_length <- length_unclean - missing_data_length
head(missing_data)
missing_data_length
clean_data_length

# calculate median
clean <- laptops_unclean$Price_euros %>% na.omit()
medianDF_clean <- median(clean)
meanDF_clean <- mean(clean)
medianDF_clean
meanDF_clean

# Impute constant value 0 and print the head
laptops_impute_0 <- laptops_unclean %>% mutate(Price_euros = replace(Price_euros, is.na(Price_euros), 0))
medianDF <- median(laptops_impute_0$Price_euros)
meanDF <- mean(laptops_impute_0$Price_euros)
head(laptops_impute_0)
medianDF
meanDF

# Impute median price and print the head
laptops_impute_med <- laptops_unclean %>% mutate(Price_euros = replace(Price_euros, is.na(Price_euros), medianDF_clean))
medianDF <- median(laptops_impute_med$Price_euros)
meanDF <- mean(laptops_impute_med$Price_euros)
head(laptops_impute_med)
medianDF
meanDF

# Das Ändern der fehlenden Werte hat Auswirkungen auf die Statistik des Data Sets. Insgesamt gibt es 1291 korrekte Datensätze. Der Median des bereinigten Datensets ist 977, der Mean liegt bei 1124.677. 
# Setzt man für die fehlenden Werte 0 ein verringert sich der Median auf 960, da der Datensatz ingesamt mehr Werte enthält und neue, kleinere Werte hinzukommen. Der Mean verringert sich auf 1114.319.
# Beim Einsetzen des Medians ändert sich der insgesamte Median im Vergleich zum bereinigten Datenset nicht (da der gleiche Wert eingesetzt wird), er ist bleibt bei 977. Der Mean verringert sich allerdings geringfügig auf 1123.317.
```




# Aufgabe 4: Identifizierung von Ausreißern [4 Punkte]
Lassen Sie uns mit unserem Laptops-Datensatz weitermachen und einige Ausreißer bekämpfen, die sich verstecken. In dieser Übung werden wir uns an die  Technik halten, anhand von Standardabweichungen zur Identifizierung von Extremwerten, da diese Methode in der Praxis häufiger verwendet wird.

Sie berechnen die deskriptiven Statistiken und Ausreißergrenzen und identifizieren dann die Zeilen mit ihnen, bevor Sie sie aus dem Dataset entfernen. Sie werden hier hauptsächlich mit der Spalte Preis arbeiten.

## Anweisungen
- Berechnen Sie den Mittelwert und die Standardabweichung der Preis-Spalte
- Berechnen Sie die oberen und unteren Grenzen von akzeptablen Werten mit 3 Standardabweichungen
- Berechnen Sie die Outliers, die ausserhalb liegen
- Verwerfen Sie die Outliers

```{r}
price <- laptops_unclean %>% filter(!is.na(Price_euros))
price <- price$Price_euros

# Calculate the mean and std
laptops_price_mean <- mean(price)
laptops_price_std <- sd(price)

laptops_price_mean
laptops_price_std

threeSDS = laptops_price_std * 3 # 3 Standardabweichungen
threeSDS

# Compute and print the upper and lower threshold
cut_off <- c(laptops_price_mean - threeSDS, laptops_price_mean + threeSDS)
cut_off
# Da es sich um Preise handelt der Preis nicht negativ sein kann, ist die untere Grenze automatisch 0 und nicht -977.1729.
# 3 Standardabweichungen unter 0 ist kein Outlier

# Identify and print rows with outliers
outliers <- laptops_unclean %>% filter(Price_euros > cut_off[2])
outliers

# Drop the rows from the dataset
df_clean <- laptops_unclean %>% filter(Price_euros < cut_off[2])
head(df_clean)


```

# Aufgabe 6 [26 Punkte]
Für diese Aufgabe werden wir den Luftqualitätsdatensatz `airquality` verwenden, der ein Standarddatensatz in R ist.

## 6.1 Data Cleaning [1 Punkt]
Dieser Datensatz enthält einige fehlende Daten. Der Einfachheit halber werden wir sie entfernen. Denken Sie darüber nach, warum dies eine vernünftige Sache sein kann oder auch nicht. (Wir werden später auf diese Idee zurückkommen. Für den Moment wollen wir uns auf die Modellierung konzentrieren)

```{r}
data <- airquality
data_length <- nrow(data)
data_length

# see how many rows with NA values we have
# depending on how many there are, replace the values or delete them
summary(data)
# Insgesamt gibt es 44 Zeilen (Ozone 37 & Solar.R 7) mit fehlenden Werten. Wenn wir alle Werte einfach entfernen würden, würde ein Großteil der Daten verloren gehen. Deshalb müssen wir die Daten ersetzen. 

# Die Spalten Monat und Tag falsch formatiert
typeof(data$Day)
typeof(data$Month)

# Tag sollte kein Integer sein, sondern ein Faktor zwischen 1 und 31 (min und max der Spalte)
data$Day <- factor(data$Day, levels=c(1:31), ordered=TRUE)

# Monat sollte ebenfalls kein Integer sein, sondern ein Faktor zwischen 5 und 9
data$Month <- factor(data$Month, levels=5:9, labels=month.abb[5:9], ordered=TRUE)

# Die NA-Werte von Ozon und Solar.R werden mit dem Median der jeweiligen Spalten ersetzt um die Werte nicht zu sehr zu verfälschen
ozone_median <- data$Ozone %>% na.omit() %>% median()
solar_r_median <- data$Solar.R %>% na.omit() %>% median()

airquality_cleaned <- data %>% mutate(Ozone = replace(Ozone, is.na(Ozone), ozone_median))
airquality_cleaned <- airquality_cleaned %>% mutate(Solar.R = replace(Solar.R, is.na(Solar.R), solar_r_median))
head(airquality_cleaned)
```

## 6.2 Test-Train Split [2 Punkte]
Jetzt wollen wir einen Testzug mit der Aufteilung der Daten durchführen. Das heißt, wir wollen einen Trainingsdatensatz zur Anpassung unserer Modelle und einen Testdatensatz zur Auswertung unserer Modelle. Da diese Aufteilung auf zufällig ausgewählten Beobachtungen im Datensatz basiert, setzen wir zunächst einen Seed-Wert, um die gleiche Aufteilung wieder reproduzieren zu können.

```{r}
set.seed(1910837830) # Your id
data <- airquality_cleaned

# Wie groß ist die Stichprobe bei 70% ?
sample_size = round(nrow(data) * .70)
# Kreiert einen Vector mit zufälligen Zeilenummern 
index <- sample(seq_len(nrow(data)), size = sample_size)

# Neues df mit den Zeilenummern aus dem Index
trn_data <- data[index, ] # 70% 
# Neues df mit allen Zeilen, welche nicht im Index sind
tst_data <- data[-index, ] # 30%

# Test ob alles korrekt ist
nobs_trn <- nrow(trn_data)
nobs_tst <- nrow(tst_data)
nobs_trn
nobs_tst
nobs_trn + nobs_tst == nrow(data)
```
Wie viele Beobachtungen werden in der Testmenge verwendet?
46 Beobachtungen in der Testmenge, 107 im Trainings-Set


## 6.3 EDA [4 Punkte]
Wir haben bereits begonnen, mit diesen Daten zu arbeiten, aber wir sollten wirklich einen Schritt zurücktreten und uns eine Frage stellen. **Was sind diese Daten?** Wann immer Sie sich diese Frage stellen, sollten Sie sich die Daten "anschauen". Man sollte drei Dinge tun:

- Lesen Sie die Metadaten, in diesem Fall die R-Dokumentation.
  - Woher kommen diese Daten?
  - Was ist eine Beobachtung in diesem Datensatz?
  - Was sind die Variablen in diesem Datensatz?
- Betrachten Sie die Daten in tabellarischer Form. Dies kann durch Anklicken des Datensatzes im RStudio Enviroment-Panel oder durch Verwendung des View() Befehls auf dem Datensatz erfolgen.
  - Was ist der Typ der einzelnen Variablen?
  - Sind kategorische Variablen als Faktoren kodiert?
- Stellen Sie die Daten dar (Plots).

**Beantworten Sie die ersten beiden Fragen!**
1)
Die Daten sind tägliche Messungen der Luftqualität in New York von Mai bis September 1973. Sie wurden vom New York State Department of Conservation (Ozondaten) und vom National Weather Service (meteorologische Daten) bezogen.
Das df hat 153 Beobachtungen und sechs Variablen:
1:	Ozone	
2:	Solar.R	
3:	Wind	
4:	Temp	
5:	Month	
6:	Day	

2)
Im originalen Datensatz sind alle Spalten numerisch. Bei den ersten vier Variablen ist dies in Ordnung, doch die Tage und Monate sollten als Faktoren formatiert sein, da ansonsten keine korrekte Analyse des Datensatzes möglich ist (bspw. würde Dezember "besser" bewertet werden als der Januar, da 12 > 01) 

**----**

Erstellen Sie ein Diagramm, das alle möglichen Streudiagramme von zwei Variablen im Trainingsdatensatz zeigt.

```{r}
ggpairs(trn_data, columns=1:4, progress = F) + ggtitle("Airquality Dataset")
```



Da wir uns auf die Vorhersage von `Ozone` mit Hilfe von `Temp` konzentrieren werden, erstellen Sie eine Streudiagramm, das nur diese Beziehung anhand der Trainingsdaten zeigt

```{r}
ggpairs(trn_data, columns=c("Ozone","Temp"), progress = F) + ggtitle("Airquality Dataset - Ozone & Temp")
```



## 6.4 Modelle [6 Punkte]
Passen Sie insgesamt fünf Polynommodelle an die Trainingsdaten an, die zur Vorhersage von Ozon aus Temp. verwendet werden können. Verwenden Sie Polynomgrade von 1 bis 5.

```{r}
# Lineares Model (Polynom grad 1)
y <- trn_data$Ozone
x <- trn_data$Temp

ggplot() + geom_point(aes(x=x, y=y)) + geom_line(aes(x=x, y=predict(mod_1)), color="green") + xlab("Temp") + ylab("Ozone")


# Interpretation des Outputs von R von Modell 1 (möglichst vollständig/relevant, Koeffizient(en),...)


```

```{r}
month <- trn_data$Month
mod_2 <- lm(y ~ poly(x, 2))
mod_3 <- lm(y ~ poly(x, 3))
mod_4 <- lm(y ~ poly(x, 4))
mod_5 <- lm(y ~ poly(x, 5))

ggplot() + geom_point(aes(x=x, y=y, colour = factor(month))) + xlab("Temp") + ylab("Ozone") + 
  geom_line(aes(x=x, y=predict(mod_2)), color="green") +
  geom_line(aes(x=x, y=predict(mod_3)), color="orange") +
  geom_line(aes(x=x, y=predict(mod_4)), color="blue") +
  geom_line(aes(x=x, y=predict(mod_5)), color="red") 

```



Vorhersage von Ozon für eine Temperatur von 89 Grad Fahrenheit unter Verwendung des Polynommodells mit drei Graden.

```{r}
month <- trn_data$Month
mod_3 <- lm(y ~ poly(x, 3))

ggplot() + geom_point(aes(x=x, y=y, colour = factor(month))) + xlab("Temp") + ylab("Ozone") + 
  geom_line(aes(x=x, y=predict(mod_3)), color="orange")


predict_degree_3_89 <- predict(mod_3, data.frame(x = 89))
predict_degree_3_89
```

```{r, eval=F}
predict_degree_3_89.sol <- predict(mod_3, data.frame(x = 89)) #74.40082
predict_degree_3_89.sol
```


Prädiktieren Sie alle 5 Modelle für Train/Test-Daten

```{r}
# Prediction
one_pred_train <- NULL
one_pred_tst <- NULL
#... (verwendung ggf. von broom/tidy)
```

## 6.5  KNN Modell [3 Punkte]
Verwenden Sie KNN mit `k = 5`, um Vorhersagen für jede der Beobachtungen sowohl im Zug als auch in den Testdatensätzen zu treffen. Speichern Sie die Ergebnisse in Vektoren mit den Namen `knn_pred_trn` und `knn_pred_tst`.

Dazu benötigen Sie die Funktion `knn.reg()` aus dem FNN-Paket. Die knn.reg() unterscheidet sich sehr von der Funktion lm(). Prüfen Sie die Dokumentation!

```{r}
library(FNN)
mod_knn <- NULL
```


- Beschreiben Sie kurz KNN
- Interpretieren Sie den Model-Output?

## 6.6 Ergebnisse [3 Punkte]
Berechnen Sie sowohl den Trainings- als auch den Test-RMSE für die obigen Modelle unter Verwendung der von Ihnen gespeicherten Vorhersagen

```{r}
# 10 rmse -> copy paste

rmse_trn_1 <- NULL
rmse_tst_1 <- NULL

rmse_trn_2 <- NULL
rmse_tst_2 <- NULL

rmse_trn_3 <- NULL
rmse_tst_3 <- NULL

rmse_trn_4 <- NULL
rmse_tst_4 <- NULL

rmse_trn_5 <- NULL
rmse_tst_5 <- NULL

# skalierung der modelle ist wichtig (dollar vs. 1000 irgendwas)
```


Berechnen Sie die R2 Scores der Modelle

```{r}
r2_trn_1 <- NULL
#...
```



Erstellen Sie eine Tabelle, die die Ergebnisse der einzelnen Modellanpassungen zusammenfasst. (Die fünf Polynommodelle und das einzelne KNN-Modell.) Notieren Sie für jedes Modell den Modelltyp, den Wert des Abstimmparameters, den Zug-RMSE und den Test-RMSE. (Betrachten Sie den Polynomgrad als Abstimmungsparameter.) Das Ergebnis sollte eine Tabelle mit einer Überschrift, sechs Zeilen und vier Spalten sein. Blenden Sie im endgültigen gerenderten Dokument den Code aus, der zur Erstellung der Tabelle verwendet wurde.

Hinweis: Erstellen Sie zuerst einen Datenrahmen und verwenden Sie dann die kable() Funktion aus dem knitr-Paket. 

```{r}
library(knitr)
library(kableExtra)
```

## 6.7 Plot der Ergebnisse [2 Punkte]
Stellen Sie die obige Streudiagramm von Ozon gegen die Temperaturform wieder her. Fügen Sie zu dieser Darstellung das Polynommodell hinzu, das am besten funktioniert hat, sowie das angepasste KNN-Modell. Können Sie diese Darstellung im gerenderten Dokument zentrieren? Blenden Sie den Code wieder aus, um die Darstellung zu erstellen.

```{r}

```

## 6.8 Multiple Prädiktoren [5 Punkte]
Bisher haben wir nur einen der verfügbaren Prädiktoren verwendet. Warum nicht alle verwenden? (Vielleicht sollten wir aber nur einige davon verwenden... Wir kommen später noch einmal auf diesen Gedanken zurück.)

[Übung] Fitten Sie ein additives lineares Modell mit Ozon als Antwort und den restlichen Variablen als Prädiktoren ein. Berechnen Sie den Test-RMSE für dieses Modell. Verbessert dies die vorherigen Modelle?

```{r}
# your code
# RMSE von 18
```

```{r, eval=F}


# Lösung, nur noch interpretieren
add_mod = lm(Ozone ~ ., data = trn_data)
calc_rmse(actual = tst_data$Ozone,
          predicted = predict(add_mod, tst_data)) # RMSE 18.87183
```


# optional
- Wie kann man die "ideale" Anzahl von Prädiktoren finden?
- Welche müssen als "Faktor" behandelt werden? Welche sind sinnvoll? Dummy-Coding
# Im Noramfall berechnet R die benätigten Daten als "Faktor"
- Welche Prädiktoren sind Korreliert? Wenn ja, welche? Wenn nein, warum (Plot)? # ggpairs
- Gibt es Confounder? Wenn ja, welche? Wenn nein, warum (Plot)? # immer plot dazu
- Gibt es Interaktionen, die Modelliert werden sollten? Wenn ja, welche? Wenn nein, warum (Plot)? # immer plot dazu
- Gibt es Outlier, Heteroskedastizität, Nicht-Normalverteilung?
# Es ist Heterodesktast, aber es ist nicht so extrem wie es aussieht. 



